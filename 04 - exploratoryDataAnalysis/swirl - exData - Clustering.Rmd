---
title: "R Notebook"
output: html_notebook
---

| Welcome to swirl! Please sign in. If you've been here before, use the same
| name as you did then. If you are new, call yourself something unique.

What shall I call you? Denis

| Would you like to continue with one of these lessons?

1: Exploratory Data Analysis Clustering Example
2: No. Let me start something new.

Selection: 1

| Attempting to load lesson dependencies...

| Package ‘fields’ loaded correctly!

| Package ‘jpeg’ loaded correctly!

| Package ‘datasets’ loaded correctly!



| We've loaded data from this study for you in a matrix called ssd.  Run the R
| command dim now to see its dimensions.

> 1
[1] 1

| One more time. You can do it! Or, type info() for more options.

| Type dim(ssd) at the command prompt.

> dim(ssd)
[1] 7352  563

| You are really on a roll!

  |======                                                                 |   8%
| Wow - ssd is pretty big, 7352 observations, each of 563 variables. Don't worry
| we'll only use a small portion of this "Human Activity Recognition database".

...

  |=======                                                                |   9%
| The study creating this database involved 30 volunteers "performing activities
| of daily living (ADL) while carrying a waist-mounted smartphone with embedded
| inertial sensors. ... Each person performed six activities ... wearing a
| smartphone (Samsung Galaxy S II) on the waist. ... The experiments have been
| video-recorded to label the data manually.  The obtained dataset has been
| randomly partitioned into two sets, where 70% of the volunteers was selected
| for generating the training data and 30% the test data."

...

  |========                                                               |  11%
| Use the R command names with just the last two columns (562 and 563) of ssd to
| see what data they contain.

> 1
[1] 1

| Not quite right, but keep trying. Or, type info() for more options.

| Type names(ssd[562:563]) at the command prompt.

> names(ssd[562:563])
[1] "subject"  "activity"

| All that hard work is paying off!

  |=========                                                              |  12%
| These last 2 columns contain subject and activity information. We saw above
| that the gathered data had "been randomly partitioned into two sets, where 70%
| of the volunteers was selected for generating the training data and 30% the
| test data." Run the R command table with ssd$subject as its argument to see if
| the data in ssd contains training or test data.

> View(ssd)

| One more time. You can do it! Or, type info() for more options.

| Type table(ssd$subject) at the command prompt.data."

> table(ssd$subject)

  1   3   5   6   7   8  11  14  15  16  17  19  21  22  23  25  26  27  28  29 
347 341 302 325 308 281 316 323 328 366 368 360 408 321 372 409 392 376 382 344 
 30 
383 

| That's correct!

  |==========                                                             |  14%
| From the number of subjects, would you infer that ssd contains training or
| test data?

1: training
2: test

Selection: 1

| You nailed it! Good job!

  |===========                                                            |  16%
| So ssd contains only training data. If you ran the R command sum with
| table(ssd$subject) as its argument, what would the number you get back
| represent?

1: Huh?
2: the number of columns in ssd
3: the number of rows in ssd
4: the number of rows and columns of ssd

Selection: 2

| Not quite right, but keep trying.

| Each row was labeled with one subject and the output from table(ssd$subject)
| told you how many rows each subject contributed to the study.

1: the number of columns in ssd
2: the number of rows and columns of ssd
3: Huh?
4: the number of rows in ssd

Selection: 1

| Try again. Getting it right on the first try is boring anyway!

| Each row was labeled with one subject and the output from table(ssd$subject)
| told you how many rows each subject contributed to the study.

1: the number of columns in ssd
2: Huh?
3: the number of rows and columns of ssd
4: the number of rows in ssd

Selection: 1

| Not exactly. Give it another go.

| Each row was labeled with one subject and the output from table(ssd$subject)
| told you how many rows each subject contributed to the study.

1: Huh?
2: the number of rows and columns of ssd
3: the number of columns in ssd
4: the number of rows in ssd

Selection: 1

| Not quite, but you're learning! Try again.

| Each row was labeled with one subject and the output from table(ssd$subject)
| told you how many rows each subject contributed to the study.

1: the number of columns in ssd
2: the number of rows in ssd
3: Huh?
4: the number of rows and columns of ssd

Selection: 1

| Keep trying!

| Each row was labeled with one subject and the output from table(ssd$subject)
| told you how many rows each subject contributed to the study.

1: the number of rows and columns of ssd
2: Huh?
3: the number of rows in ssd
4: the number of columns in ssd

Selection: 1

| Give it another try.

| Each row was labeled with one subject and the output from table(ssd$subject)
| told you how many rows each subject contributed to the study.

1: the number of columns in ssd
2: Huh?
3: the number of rows in ssd
4: the number of rows and columns of ssd

Selection: 1

| Not exactly. Give it another go.

| Each row was labeled with one subject and the output from table(ssd$subject)
| told you how many rows each subject contributed to the study.

1: the number of rows and columns of ssd
2: the number of columns in ssd
3: the number of rows in ssd
4: Huh?

Selection: 1

| Keep trying!

| Each row was labeled with one subject and the output from table(ssd$subject)
| told you how many rows each subject contributed to the study.

1: the number of rows and columns of ssd
2: the number of columns in ssd
3: the number of rows in ssd
4: Huh?

Selection: 1

| Almost! Try again.

| Each row was labeled with one subject and the output from table(ssd$subject)
| told you how many rows each subject contributed to the study.

1: the number of rows in ssd
2: the number of columns in ssd
3: Huh?
4: the number of rows and columns of ssd

Selection: 1

| You are amazing!

  |============                                                           |  17%
| Try it now (running sum on table(ssd$subject))to see if you get 7352, the
| number of rows in ssd, as a result.

> 1
[1] 1

| Not quite right, but keep trying. Or, type info() for more options.

| Type sum(table(ssd$subject)) at the command prompt.

> sum(table(ssd$subject))
[1] 7352

| That's correct!

  |=============                                                          |  19%
| So we're looking at training data from a machine learning repository. We can
| infer that this data is supposed to train machines to recognize activity
| collected from the accelerometers and gyroscopes built into the smartphones
| that the subjects had strapped to their waists. Run the R command table on
| ssd$activity to see what activities have been characterized by this data.

> 1
[1] 1

| That's not exactly what I'm looking for. Try again. Or, type info() for more
| options.

| Type table(ssd$activity) at the command prompt.

> table(ssd$activity)

  laying  sitting standing     walk walkdown   walkup 
    1407     1286     1374     1226      986     1073 

| Keep up the great work!

  |==============                                                         |  20%
| We have 6 activities, 3 passive (laying, standing and sitting) and 3 active
| which involve walking. If you ran the R command sum with table(ssd$activity)
| as its argument, what would the number you get back represent?

1: the number of rows in ssd
2: the number of rows and columns of ssd
3: the number of columns in ssd
4: Huh?

Selection: 1

| Perseverance, that's the answer.

  |================                                                       |  22%
| Because it's training data, each row is labeled with the correct activity
| (from the 6 possible) and associated with the column measurements (from the
| accelerometer and gyroscope). We're interested in questions such as, "Is the
| correlation between the measurements and activities good enough to train a
| machine?" so that "Given a set of 561 measurements, would a trained machine be
| able to determine which of the 6 activities the person was doing?"

...

  |=================                                                      |  23%
| First, let's massage the data a little so it's easier to work with. We've
| already run the R command transform on the data so that activities are
| factors. This will let us color code them when we generate plots. Let's look
| at only the first subject (numbered 1). Create the variable sub1 by assigning
| to it the output of the R command subset with ssd as the first argument and
| the boolean, subject equal to 1, as the second.

> 
> 1
[1] 1

| Nice try, but that's not exactly what I was hoping for. Try again. Or, type
| info() for more options.

| Type sub1 <- subset(ssd, subject == 1) at the command prompt.

> sub1 <- subset(ssd, subject == 1)

| Your dedication is inspiring!

  |==================                                                     |  25%
| Look at the dimensions of sub1 now.

> View(sub1)

| That's not the answer I was looking for, but try again. Or, type info() for
| more options.

| Type dim(sub1) at the command prompt.

> dim(sub1)
[1] 347 563

| Keep up the great work!

  |===================                                                    |  27%
| So sub1 has fewer than 400 rows now, but still a lot of columns which contain
| measurements. Use names on the first 12 columns of sub1 to see what kind of
| data we have.

> 1
[1] 1

| Give it another try. Or, type info() for more options.

| Type names(sub1[1:12]) at the command prompt.

> names(sub1[1:12])
 [1] "tBodyAcc.mean...X" "tBodyAcc.mean...Y" "tBodyAcc.mean...Z"
 [4] "tBodyAcc.std...X"  "tBodyAcc.std...Y"  "tBodyAcc.std...Z" 
 [7] "tBodyAcc.mad...X"  "tBodyAcc.mad...Y"  "tBodyAcc.mad...Z" 
[10] "tBodyAcc.max...X"  "tBodyAcc.max...Y"  "tBodyAcc.max...Z" 

| All that practice is paying off!

  |====================                                                   |  28%
| We see X, Y, and Z (3 dimensions) of different aspects of body acceleration
| measurements, such as mean and standard deviation. Let's do some comparisons
| of activities now by looking at plots of mean body acceleration in the X and Y
| directions. Call the function myedit with the string "showXY.R" to see the
| code generating the plots. Make sure your cursor is back in the console window
| before you hit any more buttons.

> 1
[1] 1

| Not exactly. Give it another go. Or, type info() for more options.

| Type myedit("showXY.R") at the command prompt.

> myedit("showXY.R")

| You nailed it! Good job!

  |=====================                                                  |  30%
| You see both the code and its output! The plots are a little squished, but we
| see that the active activities related to walking (shown in the two blues and
| magenta) show more variability than the passive activities (shown in black,
| red, and green), particularly in the X dimension.

...

  |======================                                                 |  31%
| The colors are a little hard to distinguish. Just for fun, call the function
| showMe (we used it in the Working_with_Colors lesson) which displays color
| vectors. Use the vector 1:6 as its argument, and hopefully this will clarify
| the colors you see in the XY comparison plot.

> 
> 1
[1] 1

| One more time. You can do it! Or, type info() for more options.

| Type showMe(1:6) at the command prompt.

> showMe(1:6)

| That's a job well done!

  |=======================                                                |  33%
| Nice! We just wanted to show you the beauty and difference in colors. The
| colors at the bottom, black, red and green, mark the passive activities, while
| the true blues and magenta near the top show the walking activities. Let's try
| clustering to see if we can distinguish the activities more.

...

  |========================                                               |  34%
| We'll still focus on the 3 dimensions of mean acceleration. (The plot we just
| saw looked at the first 2 dimensions.) Create a distance matrix, mdist, of the
| first 3 columns of sub1, by using the R command dist. Use the x[,1:3] notation
| to specify the columns.

> 1
[1] 1

| That's not the answer I was looking for, but try again. Or, type info() for
| more options.

| Type mdist <- dist(sub1[,1:3]) the command prompt.

> mdist <- dist(sub1[,1:3])

| You're the best!

  |==========================                                             |  36%
| Now create the variable hclustering by calling the R command hclust and
| passing it mdist as an argument. This will use the Euclidean distance as its
| default metric.

> 1
[1] 1

| Not quite, but you're learning! Try again. Or, type info() for more options.

| Type hclustering <- hclust(mdist) the command prompt.

> hclustering <- hclust(mdist)

| Excellent work!

  |===========================                                            |  38%
| Now call the pretty plotting function (which we've already sourced) myplclust
| with 2 arguments. The first is hclustering, and the second is the argument
| lab.col set equal to unclass(sub1$activity).

> 1
[1] 1

| That's not exactly what I'm looking for. Try again. Or, type info() for more
| options.

| Type myplclust(hclustering, lab.col = unclass(sub1$activity)) the command
| prompt.

> myplclust(hclustering, lab.col = unclass(sub1$activity))

| All that hard work is paying off!

  |============================                                           |  39%
| Well that dendrogram doesn't look too helpful, does it? There's no clear
| grouping of colors, except that active colors (blues and magenta) are near
| each other as are the passive (black, red, and green). So average acceleration
| doesn't tell us much. How about maximum acceleration? Let's look at that for
| the first subject (in our array sub1) for the X and Y dimensions. These are in
| column 10 and 11.

...1

  |=============================                                          |  41%
| Here they are plotted side by side, X dimension on the left and Y on the
| right. The x-axis of each show the 300+ observations and the y-axis indicates
| the maximum acceleration.

...

  |==============================                                         |  42%
| From the 2 plots, what separation, if any, do you see?

1: passive activities generate the most acceleration
2: passive activities mostly fall below the walking activities
3: laying generates the most acceleration in the X dimension
4: there is no pattern

Selection: 1

| One more time. You can do it!

| There is a pattern. Which choice makes the most obvious sense?

1: passive activities generate the most acceleration
2: passive activities mostly fall below the walking activities
3: laying generates the most acceleration in the X dimension
4: there is no pattern

Selection: 2

| That's a job well done!

  |===============================                                        |  44%
| Finally we're seeing something vaguely interesting! Let's focus then on the 3
| dimensions of maximum acceleration, stored in columns 10 through 12 of sub1.
| Create a new distance matrix, mdist, of these 3 columns of sub1, by using the
| R command dist. Again, use the x[,10:12] notation to catch the columns.

> 1
[1] 1

| Almost! Try again. Or, type info() for more options.

| Type mdist <- dist(sub1[,10:12]) the command prompt.

> mdist <- dist(sub1[,10:12])

| You nailed it! Good job!

  |================================                                       |  45%
| Now create the variable hclustering by calling hclust with mdist as the
| argument.

> 1
[1] 1

| That's not exactly what I'm looking for. Try again. Or, type info() for more
| options.

| Type hclustering <- hclust(mdist) the command prompt.

> hclustering <- hclust(mdist)

| You nailed it! Good job!

  |=================================                                      |  47%
| Again, call the myplclust with 2 arguments. The first is hclustering, and the
| second is the argument lab.col set equal to unclass(sub1$activity).

> 1
[1] 1

| Not exactly. Give it another go. Or, type info() for more options.

| Type myplclust(hclustering, lab.col = unclass(sub1$activity)) the command
| prompt.

> myplclust(hclustering, lab.col = unclass(sub1$activity))

| That's the answer I was looking for.

  |==================================                                     |  48%
| Now we see clearly that the data splits into 2 clusters, active and passive
| activities. Moreover, the light blue (walking down) is clearly distinct from
| the other walking activities. The dark blue (walking level) also seems to be
| somewhat clustered. The passive activities, however, seem all jumbled together
| with no clear pattern visible.

...1

  |====================================                                   |  50%
| Let's try some SVD now. Create the variable svd1 by assigning to it the output
| of a call to the R command svd. The argument to svd should be
| scale(sub1[,-c(562,563)]). This will remove the last 2 columns from sub1 and
| scale the data. Recall that the last 2 columns contain activity and subject
| information which we won't need.

> 
> 1
[1] 1

| Not quite, but you're learning! Try again. Or, type info() for more options.

| Type svd1 <- svd(scale(sub1[,-c(562,563)])) the command prompt.

> svd1 <- svd(scale(sub1[,-c(562,563)]))

| Excellent job!

  |=====================================                                  |  52%
| To see LEFT singular vectors of sub1, which component of svd1 would we
| examine?

1: v
2: x
3: d
4: u

Selection: 2

| You almost had it, but not quite. Try again.

| One of the choices isn't even part of the svd output. Recall that singular
| value decomposition expresses the matrix X as the product of three other
| matrices, X=UDV. Which of these is leftmost?

1: u
2: d
3: v
4: x

Selection: 1

| Keep up the great work!

  |======================================                                 |  53%
| Call the R command dim with svd1$u as an argument.

> dim(svd1$u)
[1] 347 347

| You are doing so well!

  |=======================================                                |  55%
| We see that the u matrix is a 347 by 347 matrix. Each row in u corresponds to
| a row in the matrix sub1. Recall that in sub1 each row has an associated
| activity.

...

  |========================================                               |  56%
| Here we're looking at the 2 left singular vectors of svd1 (the first 2 columns
| of svd1$u). Each entry of the columns belongs to a particular row with one of
| the 6 activities assigned to it. We see the activities distinguished by color.
| Moving from left to right, the first section of rows are green (standing), the
| second red (sitting), the third black (laying), etc.  The first column of u
| shows separation of the nonmoving (black, red, and green) from the walking
| activities. The second column is harder to interpret. However, the magenta
| cluster, which represents walking up, seems separate from the others.

...

  |=========================================                              |  58%
| We'll try to figure out why that is. To do that we'll have to find which of
| the 500+ measurements (represented by the columns of sub1) contributes to the
| variation of that component. Since we're interested in sub1 columns, we'll
| look at the RIGHT singular vectors (the columns of svd1$v), and in particular,
| the second one since the separation of the magenta cluster stood out in the
| second column of svd1$u.

...

  |==========================================                             |  59%
| Here's a plot of the second column of svd1$v. We used transparency in our
| plotting but nothing clearly stands out here. Let's use clustering to find the
| feature (out of the 500+) which contributes the most to the variation of this
| second column of svd1$v.

...

  |===========================================                            |  61%
| Create the variable maxCon by assigning to it the output of the R command
| which.max using the second column of svd1$v as an argument.

> 
> 1
[1] 1

| Not exactly. Give it another go. Or, type info() for more options.

| Type maxCon <- which.max(svd1$v[,2]) at the command prompt.

> maxCon <- which.max(svd1$v[,2])

| Perseverance, that's the answer.

  |============================================                           |  62%
| Now create a distance matrix mdist by assigning to it the output of the R
| command dist using 4 columns of sub1 as the arguments. These 4 columns are 10
| through 12 (10:12) and maxCon. Recall that you'll have to concatenate these 2
| column expressions when specifying them.

> 1
[1] 1

| That's not exactly what I'm looking for. Try again. Or, type info() for more
| options.

| Type mdist <- dist(sub1[,c(10:12,maxCon)]) at the command prompt.

> mdist <- dist(sub1[,c(10:12,maxCon)])

| You nailed it! Good job!

  |=============================================                          |  64%
| Now create hclustering, the output of the R command hclust using mdist as the
| argument.

> 1
[1] 1

| That's not the answer I was looking for, but try again. Or, type info() for
| more options.

| Type hclustering <- hclust(mdist) at the command prompt.

> hclustering <- hclust(mdist)

| Great job!

  |===============================================                        |  66%
| Call the myplclust with 2 arguments, hclustering, and lab.col set equal to
| unclass(sub1$activity).

> 1
[1] 1

| Give it another try. Or, type info() for more options.

| Type myplclust(hclustering, lab.col = unclass(sub1$activity)) at the command
| prompt.

> myplclust(hclustering, lab.col = unclass(sub1$activity))

| You got it right!

  |================================================                       |  67%
| Now we see some real separation. Magenta (walking up) is on the far left, and
| the two other walking activities, the two blues, are on the far right, but in
| separate clusters from one another. The nonmoving activities still are jumbled
| together.

...

  |=================================================                      |  69%
| Run the R command names with the argument sub1[maxCon] to see what measurement
| is associated with this maximum contributor.

> 1
[1] 1

| Keep trying! Or, type info() for more options.

| Type names(sub1[maxCon]) or names(sub1)[maxCon] at the command prompt.

> names(sub1[maxCon])
[1] "fBodyAcc.meanFreq...Z"

| Excellent job!

  |==================================================                     |  70%
| So the mean body acceleration in the frequency domain in the Z direction is
| the main contributor to this clustering phenomenon we're seeing. Let's move on
| to k-means clustering to see if this technique can distinguish between the
| activities.

...

  |===================================================                    |  72%
| Create the variable kClust by assigning to it the output of the R command
| kmeans with 2 arguments. The first is sub1 with the last 2 columns removed.
| (Recall these don't have pertinent information for clustering analysis.) The
| second argument to kmeans is centers set equal to 6, the number of activities
| we know we have.

> 
> 1
[1] 1

| Not quite, but you're learning! Try again. Or, type info() for more options.

| Type kClust <- kmeans(sub1[, -c(562, 563)], centers = 6) the command prompt.

> kClust <- kmeans(sub1[, -c(562, 563)], centers = 6)

| You are really on a roll!

  |====================================================                   |  73%
| Recall that without specifying coordinates for the cluster centroids (as we
| did), kmeans will generate starting points randomly. Here we did only 1 random
| start (the default). To see the output, run the R command table with 2
| arguments. The first is kClust$cluster (part of the output from kmeans), and
| the second is sub1$activity.

> 1
[1] 1

| That's not exactly what I'm looking for. Try again. Or, type info() for more
| options.

| Type table(kClust$cluster, sub1$activity) the command prompt.

> table(kClust$cluster, sub1$activity)
   
    laying sitting standing walk walkdown walkup
  1     27      37       51    0        0      0
  2      0       0        0   27        0      0
  3      0       0        0   68        1      0
  4     20      10        2    0        0      0
  5      3       0        0    0        0     53
  6      0       0        0    0       48      0

| Nice work!

  |=====================================================                  |  75%
| Your exact output will depend on the state of your random number generator. We
| notice that when we just run with 1 random start, the clusters tend to group
| the nonmoving activities together in one cluster. The walking activities seem
| to cluster individually by themselves. You could run the call to kmeans with
| one random start again and you'll probably get a slightly different result,
| but....

...1

  |======================================================                 |  77%
| ... instead call kmeans with 3 arguments, the last of which will tell it to
| try more random starts and return the best one. The first 2 arguments should
| be the same as before (sub1 with the last 2 columns removed and centers set
| equal to 6). The third is nstart set equal to 100. Put the result in kClust
| again.

> 1
[1] 1

| Not exactly. Give it another go. Or, type info() for more options.

| Type kClust <- kmeans(sub1[, -c(562, 563)], centers = 6, nstart=100) the
| command prompt.

> kClust <- kmeans(sub1[, -c(562, 563)], centers = 6, nstart=100)

| You got it!

  |=======================================================                |  78%
| Again, run the R command table with 2 arguments. The first is kClust$cluster
| (part of the output from kmeans), and the second is sub1$activity.

> 1
[1] 1

| You almost had it, but not quite. Try again. Or, type info() for more options.

| Type table(kClust$cluster, sub1$activity) the command prompt.

> table(kClust$cluster, sub1$activity)
   
    laying sitting standing walk walkdown walkup
  1      0      37       51    0        0      0
  2      3       0        0    0        0     53
  3     18      10        2    0        0      0
  4     29       0        0    0        0      0
  5      0       0        0    0       49      0
  6      0       0        0   95        0      0

| Great job!

  |=========================================================              |  80%
| We see that even with 100 random starts, the passive activities tend to
| cluster together. One of the clusters contains only laying, but in another
| cluster, standing and sitting group together.

...

  |==========================================================             |  81%
| Use dim to find the dimensions of kClust's centers. Use the x$y notation to
| access them.

> 1
[1] 1

| Not quite! Try again. Or, type info() for more options.

| Type dim(kClust$centers) the command prompt.

> dim(kClust$centers)
[1]   6 561

| You're the best!

  |===========================================================            |  83%
| So the centers are a 6 by 561 array. Sometimes it's a good idea to look at the
| features (columns) of these centers to see if any dominate.

...

  |============================================================           |  84%
| Create the variable laying and assign to it the output of the call to the R
| command which with the argument kClust$size==29.

> 1
[1] 1

| Almost! Try again. Or, type info() for more options.

| Type laying <- which(kClust$size==29) the command prompt.

> laying <- which(kClust$size==29)

| Excellent job!

  |=============================================================          |  86%
| Now call plot with 3 arguments. The first is kClust$centers[laying,1:12], and
| the second is pch set to 19. The third is ylab set equal to "Laying Cluster"

> 1
[1] 1

| Almost! Try again. Or, type info() for more options.

| Type plot(kClust$centers[laying, 1:12],pch=19,ylab="Laying Cluster") the
| command prompt.

> plot(kClust$centers[laying, 1:12],pch=19,ylab="Laying Cluster")

| All that hard work is paying off!

  |==============================================================         |  88%
| We see the first 3 columns dominate this cluster center. Run names with the
| first 3 columns of sub1 as the argument to remind yourself of what these
| columns contain.

> 
> 1
[1] 1

| Not exactly. Give it another go. Or, type info() for more options.

| Type names(sub1[,1:3]) the command prompt.

> names(sub1[,1:3])
[1] "tBodyAcc.mean...X" "tBodyAcc.mean...Y" "tBodyAcc.mean...Z"

| That's correct!

  |===============================================================        |  89%
| So the 3 directions of mean body acceleration seem to have the biggest effect
| on laying.

...1

  |================================================================       |  91%
| Create the variable walkdown and assign to it the output of the call to the R
| command which with the argument kClust$size==49.

> 
> 1
[1] 1

| Not exactly. Give it another go. Or, type info() for more options.

| Type walkdown <- which(kClust$size==49) the command prompt.

> walkdown <- which(kClust$size==49)

| You are really on a roll!

  |=================================================================      |  92%
| Now call plot with 3 arguments. The first is kClust$centers[walkdown,1:12],
| and the second is pch set to 19. The third is ylab set equal to "Walkdown
| Cluster"

> 1
[1] 1

| Not quite, but you're learning! Try again. Or, type info() for more options.

| Type plot(kClust$centers[walkdown, 1:12],pch=19,ylab="Walkdown Cluster") the
| command prompt.

> plot(kClust$centers[walkdown, 1:12],pch=19,ylab="Walkdown Cluster")

| You nailed it! Good job!

  |===================================================================    |  94%
| We see an interesting pattern here. From left to right, looking at the 12
| acceleration measurements in groups of 3, the points decrease in value. The X
| direction dominates, followed by Y then Z. This might tell us something more
| about the walking down activity.

...

  |====================================================================   |  95%
| We'll wrap up here and hope this example convinced you that real world
| analysis can be frustrating sometimes and not always obvious. You might have
| to try several techniques of exploratory data analysis before you hit one that
| pays off and leads you to the questioms that will be the most promising to
| explore.

...

  |=====================================================================  |  97%
| We saw here that the sensor measurements were pretty good at discriminating
| between the 3 walking activities, but the passive activities were harder to
| distinguish from one another. These might require more analysis or an entirely
| different set of sensory measurements.

...

  |====================================================================== |  98%
| Congratulations! We hope you enjoyed the 6 activities and 500+ features of
| this lesson.

...

  |=======================================================================| 100%
| Would you like to receive credit for completing this course on Coursera.org?

1: No
2: Yes

Selection: 2
What is your email address? lopes.denis@gmail.com
What is your assignment token? IvG8Ef0aE8IBmYwP
Grade submission succeeded!

| Excellent work!

| You've reached the end of this lesson! Returning to the main menu...

| Please choose a course, or type 0 to exit swirl.

1: Exploratory Data Analysis
2: Take me to the swirl course repository!